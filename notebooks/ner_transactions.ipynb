{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from seqeval.metrics import classification_report, f1_score , precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = '[PAD]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label tokens\n",
    "def label_tokens(sms, amount, store, balance, date, time, max_len=50):\n",
    "    tokens = nltk.word_tokenize(sms)\n",
    "    labels = []\n",
    "    for token in tokens:\n",
    "        if token in [':', '/', '.'] or token.isdigit():\n",
    "            labels.append((token, 'O'))\n",
    "        elif token in str(amount):\n",
    "            labels.append((token, 'B-AMOUNT'))\n",
    "        elif token in store.split():\n",
    "            labels.append((token, 'B-STORE'))\n",
    "        elif token in balance:\n",
    "            labels.append((token, 'B-BALANCE'))\n",
    "        elif token in date:\n",
    "            labels.append((token, 'B-DATE'))\n",
    "        elif token in time:\n",
    "            labels.append((token, 'B-TIME'))\n",
    "        else:\n",
    "            labels.append((token, 'O'))\n",
    "    # check if a token repeats, use B-I-O tagging\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "        if i != 0 and labels[i][1] != 'O' : \n",
    "            if labels[i-1][1] == \"O\" : \n",
    "                continue \n",
    "            elif labels[i-1][1].split(\"-\")[1] != labels[i][1].split(\"-\")[1]:\n",
    "                continue \n",
    "            elif labels[i-1][1].split(\"-\")[1] == labels[i][1].split(\"-\")[1]:\n",
    "                labels[i] = (labels[i][0], labels[i][1].replace(\"B-\", \"I-\"))\n",
    "\n",
    "    # pad the labels\n",
    "    if len(labels) < max_len:\n",
    "        pad_length = max_len - len(labels)\n",
    "        labels.extend([(PAD_TOKEN, 'O')] * pad_length)\n",
    "    else : \n",
    "        raise ValueError('The length of the tokens is greater than the max_len')\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>type</th>\n",
       "      <th>card_number</th>\n",
       "      <th>amount</th>\n",
       "      <th>store</th>\n",
       "      <th>account</th>\n",
       "      <th>balance</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your card ending in ****7242 was debited QAR 6...</td>\n",
       "      <td>temp0</td>\n",
       "      <td>****7242</td>\n",
       "      <td>681.29</td>\n",
       "      <td>9A8ts5Zaq b   v</td>\n",
       "      <td>***370022</td>\n",
       "      <td>9,565.07</td>\n",
       "      <td>04/10/20</td>\n",
       "      <td>13:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alert: QAR 443.09 was spent at XiTi U dvQPm85u...</td>\n",
       "      <td>temp1</td>\n",
       "      <td>****5617</td>\n",
       "      <td>443.09</td>\n",
       "      <td>XiTi U dvQPm85ujTBTHA</td>\n",
       "      <td>***122717</td>\n",
       "      <td>1,408.17</td>\n",
       "      <td>03/08/23</td>\n",
       "      <td>13:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transaction Notice: QAR 1,106.03 was debited f...</td>\n",
       "      <td>temp2</td>\n",
       "      <td>****5583</td>\n",
       "      <td>1,106.03</td>\n",
       "      <td>Svjec67ZhS</td>\n",
       "      <td>***233856</td>\n",
       "      <td>6,771.83</td>\n",
       "      <td>23/12/20</td>\n",
       "      <td>19:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Your card ending in ****7854 was charged QAR 1...</td>\n",
       "      <td>temp3</td>\n",
       "      <td>****7854</td>\n",
       "      <td>1,232.12</td>\n",
       "      <td>pyFX1fTK-qzV2Q1uD</td>\n",
       "      <td>***184486</td>\n",
       "      <td>3,512.70</td>\n",
       "      <td>06/04/20</td>\n",
       "      <td>07:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QAR 1,366.30 was debited from your account end...</td>\n",
       "      <td>temp4</td>\n",
       "      <td>****8680</td>\n",
       "      <td>1,366.30</td>\n",
       "      <td>LQHiAX3EYn0</td>\n",
       "      <td>***511829</td>\n",
       "      <td>5,843.34</td>\n",
       "      <td>27/06/20</td>\n",
       "      <td>05:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>Update: Purchase of 790.54 at hZjYt aU0wHdM9mX...</td>\n",
       "      <td>temp26</td>\n",
       "      <td>****7563</td>\n",
       "      <td>790.54</td>\n",
       "      <td>hZjYt aU0wHdM9mX6VfmOe3ag</td>\n",
       "      <td>***939242</td>\n",
       "      <td>133.89</td>\n",
       "      <td>28/12/22</td>\n",
       "      <td>06:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>Bank Alert: 170.13 debited from account ***350...</td>\n",
       "      <td>temp27</td>\n",
       "      <td>****5217</td>\n",
       "      <td>170.13</td>\n",
       "      <td>N x ur8JK0p2Tz p6stzt</td>\n",
       "      <td>***350969</td>\n",
       "      <td>1,303.09</td>\n",
       "      <td>26/10/21</td>\n",
       "      <td>14:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>Notification: Card ****7105 transaction at vOh...</td>\n",
       "      <td>temp28</td>\n",
       "      <td>****7105</td>\n",
       "      <td>535.83</td>\n",
       "      <td>vOhqbfURJeM9R6EgoiZMN</td>\n",
       "      <td>***119815</td>\n",
       "      <td>7,610.56</td>\n",
       "      <td>11/12/23</td>\n",
       "      <td>21:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>FYI: A 1,473.24 purchase at bn P2w u FXGXGdf6C...</td>\n",
       "      <td>temp29</td>\n",
       "      <td>****8299</td>\n",
       "      <td>1,473.24</td>\n",
       "      <td>bn P2w u FXGXGdf6C8</td>\n",
       "      <td>***862604</td>\n",
       "      <td>2,803.16</td>\n",
       "      <td>29/08/22</td>\n",
       "      <td>16:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>Transaction Alert: Card ****2559 used at 5R-V ...</td>\n",
       "      <td>temp30</td>\n",
       "      <td>****2559</td>\n",
       "      <td>605.41</td>\n",
       "      <td>5R-V XjZsvs2JPpTZ85</td>\n",
       "      <td>***604722</td>\n",
       "      <td>3,965.74</td>\n",
       "      <td>08/04/20</td>\n",
       "      <td>22:37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6200 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sms    type card_number  \\\n",
       "0     Your card ending in ****7242 was debited QAR 6...   temp0    ****7242   \n",
       "1     Alert: QAR 443.09 was spent at XiTi U dvQPm85u...   temp1    ****5617   \n",
       "2     Transaction Notice: QAR 1,106.03 was debited f...   temp2    ****5583   \n",
       "3     Your card ending in ****7854 was charged QAR 1...   temp3    ****7854   \n",
       "4     QAR 1,366.30 was debited from your account end...   temp4    ****8680   \n",
       "...                                                 ...     ...         ...   \n",
       "6195  Update: Purchase of 790.54 at hZjYt aU0wHdM9mX...  temp26    ****7563   \n",
       "6196  Bank Alert: 170.13 debited from account ***350...  temp27    ****5217   \n",
       "6197  Notification: Card ****7105 transaction at vOh...  temp28    ****7105   \n",
       "6198  FYI: A 1,473.24 purchase at bn P2w u FXGXGdf6C...  temp29    ****8299   \n",
       "6199  Transaction Alert: Card ****2559 used at 5R-V ...  temp30    ****2559   \n",
       "\n",
       "        amount                      store    account   balance      date  \\\n",
       "0       681.29            9A8ts5Zaq b   v  ***370022  9,565.07  04/10/20   \n",
       "1       443.09      XiTi U dvQPm85ujTBTHA  ***122717  1,408.17  03/08/23   \n",
       "2     1,106.03                 Svjec67ZhS  ***233856  6,771.83  23/12/20   \n",
       "3     1,232.12          pyFX1fTK-qzV2Q1uD  ***184486  3,512.70  06/04/20   \n",
       "4     1,366.30                LQHiAX3EYn0  ***511829  5,843.34  27/06/20   \n",
       "...        ...                        ...        ...       ...       ...   \n",
       "6195    790.54  hZjYt aU0wHdM9mX6VfmOe3ag  ***939242    133.89  28/12/22   \n",
       "6196    170.13      N x ur8JK0p2Tz p6stzt  ***350969  1,303.09  26/10/21   \n",
       "6197    535.83     vOhqbfURJeM9R6EgoiZMN   ***119815  7,610.56  11/12/23   \n",
       "6198  1,473.24        bn P2w u FXGXGdf6C8  ***862604  2,803.16  29/08/22   \n",
       "6199    605.41        5R-V XjZsvs2JPpTZ85  ***604722  3,965.74  08/04/20   \n",
       "\n",
       "       time  \n",
       "0     13:55  \n",
       "1     13:34  \n",
       "2     19:33  \n",
       "3     07:11  \n",
       "4     05:37  \n",
       "...     ...  \n",
       "6195  06:08  \n",
       "6196  14:56  \n",
       "6197  21:30  \n",
       "6198  16:55  \n",
       "6199  22:37  \n",
       "\n",
       "[6200 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"data/synthetic_sms.csv\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply labeling function\n",
    "ner_data = []\n",
    "for index, row in data_df.iterrows():\n",
    "    labeled_tokens = label_tokens(row['sms'],  row['amount'], row['store'], row['balance'], row['date'], row['time'], max_len=65)\n",
    "    ner_data.append(labeled_tokens)  # Add a blank line to separate sentences\n",
    "ner_data = np.array(ner_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "# # Initialize a tokenizer with a WordPiece model\n",
    "# tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))\n",
    "# tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "# # Define a trainer with a smaller vocab size\n",
    "# trainer = trainers.WordPieceTrainer(\n",
    "#     vocab_size=5000, \n",
    "#     special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "# )\n",
    "\n",
    "# # Convert your DataFrame column to a list of strings\n",
    "# sms_texts = data_df['sms'].tolist()\n",
    "\n",
    "# # Use train_from_iterator to train on an iterator of texts\n",
    "# tokenizer.train_from_iterator(sms_texts, trainer=trainer, length=len(sms_texts))\n",
    "\n",
    "# tokenizer.save(\"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(tokenizer, ner_data, label2id, IGNORE_INDEX, max_length=120): \n",
    "    bert_tokens = []\n",
    "    for sample in ner_data:\n",
    "        tokens = sample[:,0]\n",
    "        labels = sample[:,1]\n",
    "        encoding = tokenizer(list(tokens),\n",
    "                            is_split_into_words=True,\n",
    "                            return_offsets_mapping=True,\n",
    "                            padding='max_length',\n",
    "                            truncation=True,\n",
    "                            max_length=max_length)\n",
    "\n",
    "        # encoding = tokenizer.encode(list(tokens),\n",
    "        #                      is_split_into_words=True)\n",
    "        # The tokenizer returns a list that maps each tokenized subword to its original word index.\n",
    "        word_ids = encoding.word_ids()\n",
    "\n",
    "        # fix  [labels[idx] for idx in word_ids if idx is not None else \"[pad]\"] \n",
    "        labels = [ labels[idx] if idx is not None else IGNORE_INDEX for idx in word_ids]\n",
    "\n",
    "        for i in range(len(labels)):\n",
    "            if i != 0 and labels[i] != 'O' and labels[i] != IGNORE_INDEX: \n",
    "                if labels[i-1] == \"O\" : \n",
    "                    continue \n",
    "                elif labels[i-1].split(\"-\")[1] != labels[i].split(\"-\")[1]:\n",
    "                    continue \n",
    "                elif labels[i-1].split(\"-\")[1] == labels[i].split(\"-\")[1]:\n",
    "                    labels[i] =  labels[i].replace(\"B-\", \"I-\")\n",
    "\n",
    "        labels = [label2id[label] if label != IGNORE_INDEX else IGNORE_INDEX for label in labels]\n",
    "        \n",
    "        encoding[\"labels\"] = labels \n",
    "\n",
    "        bert_tokens.append([encoding[\"input_ids\"] , encoding[\"labels\"]])\n",
    "\n",
    "    return np.array(bert_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_INDEX = 99\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B-AMOUNT\": 1,\n",
    "    \"I-AMOUNT\": 2,\n",
    "    \"B-STORE\": 3,\n",
    "    \"I-STORE\": 4,\n",
    "    \"B-BALANCE\": 5,\n",
    "    \"I-BALANCE\": 6,\n",
    "    \"B-DATE\": 7,\n",
    "    \"I-DATE\": 8,\n",
    "    \"B-TIME\": 9,\n",
    "    \"I-TIME\": 10,\n",
    "    PAD_TOKEN : IGNORE_INDEX  # We use -100 for tokens we want to ignore in the loss (e.g. padding or subword pieces)\n",
    "}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokens = tokenize_data(tokenizer, ner_data, label2id, IGNORE_INDEX, max_length=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Define a simple NER Dataset\n",
    "# ---------------------------\n",
    "class NerDataset(Dataset):\n",
    "    def __init__(self, tokens, labels):\n",
    "        self.tokens = tokens\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.tokens[idx]\n",
    "        y = self.labels[idx]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Define the LightningModule with an LSTM\n",
    "# ---------------------------\n",
    "class NerModel(pl.LightningModule):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_tags, lr=1e-3, l1=1e-4, dropout=0.3, att_heads=4):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.l1 = l1 \n",
    "        self.dropout_rate = dropout\n",
    "        self.att_heads = att_heads\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Embedding layer; padding_idx is set to IGNORE_INDEX\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=IGNORE_INDEX)\n",
    "        \n",
    "        # LSTM layer; bidirectional for richer context\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=att_heads, dropout=self.dropout_rate, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        # Fully connected layer maps attention output to number of tag classes\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_tags)\n",
    "        \n",
    "        # Loss function: ignore padding index (IGNORE_INDEX)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len]\n",
    "        x = self.embedding(x)              # [batch, seq_len, embedding_dim]\n",
    "        x, _ = self.lstm(x)                # [batch, seq_len, hidden_dim*2]\n",
    "                \n",
    "        # Apply self-attention: query, key, and value are all x\n",
    "        attn_output, attn_weights = self.attention(x, x, x)\n",
    "        attn_output = self.dropout(attn_output)\n",
    "        \n",
    "        logits = self.fc(attn_output)      # [batch, seq_len, num_tags]\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        # Flatten logits and targets for computing loss\n",
    "        loss = self.loss_fn(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self.forward(x)\n",
    "        loss = self.loss_fn(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l1)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model, dataloader, id2label):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, y = batch  # x: token ids, y: label ids (with -100 for padding/subwords)\n",
    "            logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=-1)  # shape: [batch, seq_len]\n",
    "            \n",
    "            # Convert predictions and true labels to lists, ignoring -100 tokens.\n",
    "            preds = preds.cpu().numpy()\n",
    "            y = y.cpu().numpy()\n",
    "            \n",
    "            for pred_seq, true_seq in zip(preds, y):\n",
    "                pred_labels = []\n",
    "                true_labels = []\n",
    "                for p, t in zip(pred_seq, true_seq):\n",
    "                    if t != IGNORE_INDEX:  # Ignore subwords/padding\n",
    "                        pred_labels.append(id2label.get(p, \"O\"))\n",
    "                        true_labels.append(id2label.get(t, \"O\"))\n",
    "                    else : \n",
    "                        pred_labels.append(PAD_TOKEN)\n",
    "                        true_labels.append(PAD_TOKEN)\n",
    "                all_preds.append(pred_labels)\n",
    "                all_labels.append(true_labels)\n",
    "    \n",
    "    return all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 60/60 [00:02<00:00, 26.53it/s, v_num=0, train_loss=0.00099, val_loss=0.00849] \n",
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.98      0.97      0.98      3977\n",
      "     BALANCE       0.98      1.00      0.99      4145\n",
      "        DATE       1.00      1.00      1.00      3840\n",
      "        PAD]       1.00      1.00      1.00      7680\n",
      "       STORE       1.00      1.00      1.00      3879\n",
      "        TIME       1.00      1.00      1.00      3840\n",
      "\n",
      "   micro avg       0.99      1.00      0.99     27361\n",
      "   macro avg       0.99      0.99      0.99     27361\n",
      "weighted avg       0.99      1.00      0.99     27361\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.99      0.97      0.98       999\n",
      "     BALANCE       0.97      1.00      0.99      1045\n",
      "        DATE       1.00      1.00      1.00       960\n",
      "        PAD]       1.00      1.00      1.00      1920\n",
      "       STORE       0.94      0.95      0.95       972\n",
      "        TIME       1.00      1.00      1.00       960\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6856\n",
      "   macro avg       0.98      0.99      0.99      6856\n",
      "weighted avg       0.99      0.99      0.99      6856\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.80      0.89      0.84      1471\n",
      "     BALANCE       1.00      0.93      0.96      1510\n",
      "        DATE       1.00      1.00      1.00      1400\n",
      "        PAD]       1.00      1.00      1.00      2800\n",
      "       STORE       0.30      0.56      0.39      1416\n",
      "        TIME       1.00      1.00      1.00      1400\n",
      "\n",
      "   micro avg       0.81      0.91      0.86      9997\n",
      "   macro avg       0.85      0.90      0.87      9997\n",
      "weighted avg       0.87      0.91      0.88      9997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 63/63 [00:02<00:00, 27.41it/s, v_num=1, train_loss=0.000603, val_loss=0.00538]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 63/63 [00:02<00:00, 27.29it/s, v_num=1, train_loss=0.000603, val_loss=0.00538]\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.99      1.00      1.00      4143\n",
      "     BALANCE       1.00      1.00      1.00      4309\n",
      "        DATE       1.00      1.00      1.00      4000\n",
      "        PAD]       1.00      1.00      1.00      8000\n",
      "       STORE       0.99      0.99      0.99      4046\n",
      "        TIME       1.00      1.00      1.00      4000\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     28498\n",
      "   macro avg       1.00      1.00      1.00     28498\n",
      "weighted avg       1.00      1.00      1.00     28498\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      1041\n",
      "     BALANCE       1.00      1.00      1.00      1067\n",
      "        DATE       1.00      1.00      1.00      1000\n",
      "        PAD]       1.00      1.00      1.00      2000\n",
      "       STORE       0.94      0.96      0.95      1005\n",
      "        TIME       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7113\n",
      "   macro avg       0.99      0.99      0.99      7113\n",
      "weighted avg       0.99      0.99      0.99      7113\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.64      0.83      0.72      1263\n",
      "     BALANCE       0.71      0.91      0.80      1324\n",
      "        DATE       1.00      1.00      1.00      1200\n",
      "        PAD]       1.00      1.00      1.00      2400\n",
      "       STORE       0.69      0.94      0.79      1216\n",
      "        TIME       1.00      1.00      1.00      1200\n",
      "\n",
      "   micro avg       0.83      0.95      0.89      8603\n",
      "   macro avg       0.84      0.95      0.88      8603\n",
      "weighted avg       0.86      0.95      0.90      8603\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 63/63 [00:02<00:00, 26.39it/s, v_num=2, train_loss=0.00419, val_loss=0.00687] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 63/63 [00:02<00:00, 26.36it/s, v_num=2, train_loss=0.00419, val_loss=0.00687]\n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      4191\n",
      "     BALANCE       1.00      1.00      1.00      4397\n",
      "        DATE       1.00      1.00      1.00      4000\n",
      "        PAD]       1.00      1.00      1.00      8000\n",
      "       STORE       0.97      0.99      0.98      4042\n",
      "        TIME       1.00      1.00      1.00      4000\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     28630\n",
      "   macro avg       0.99      1.00      1.00     28630\n",
      "weighted avg       1.00      1.00      1.00     28630\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      1056\n",
      "     BALANCE       0.99      1.00      1.00      1103\n",
      "        DATE       1.00      1.00      1.00      1000\n",
      "        PAD]       1.00      1.00      1.00      2000\n",
      "       STORE       0.93      0.94      0.94      1009\n",
      "        TIME       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7168\n",
      "   macro avg       0.99      0.99      0.99      7168\n",
      "weighted avg       0.99      0.99      0.99      7168\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.86      0.91      0.89      1200\n",
      "     BALANCE       0.94      0.99      0.96      1200\n",
      "        DATE       1.00      1.00      1.00      1200\n",
      "        PAD]       1.00      1.00      1.00      2400\n",
      "       STORE       0.77      0.94      0.85      1216\n",
      "        TIME       0.83      0.83      0.83      1200\n",
      "\n",
      "   micro avg       0.91      0.95      0.93      8416\n",
      "   macro avg       0.90      0.94      0.92      8416\n",
      "weighted avg       0.91      0.95      0.93      8416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 63/63 [00:02<00:00, 27.14it/s, v_num=3, train_loss=0.0077, val_loss=0.00748] \n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      0.98      0.99      4195\n",
      "     BALANCE       0.97      1.00      0.99      4399\n",
      "        DATE       1.00      1.00      1.00      4000\n",
      "        PAD]       1.00      1.00      1.00      8000\n",
      "       STORE       0.98      0.99      0.99      4046\n",
      "        TIME       1.00      1.00      1.00      4000\n",
      "\n",
      "   micro avg       0.99      1.00      0.99     28640\n",
      "   macro avg       0.99      1.00      0.99     28640\n",
      "weighted avg       0.99      1.00      0.99     28640\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      0.98      0.99      1052\n",
      "     BALANCE       0.97      1.00      0.99      1101\n",
      "        DATE       1.00      1.00      1.00      1000\n",
      "        PAD]       1.00      1.00      1.00      2000\n",
      "       STORE       0.94      0.95      0.95      1010\n",
      "        TIME       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7163\n",
      "   macro avg       0.99      0.99      0.99      7163\n",
      "weighted avg       0.99      0.99      0.99      7163\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.95      1.00      0.97      1200\n",
      "     BALANCE       0.63      1.00      0.77      1200\n",
      "        DATE       1.00      1.00      1.00      1200\n",
      "        PAD]       1.00      1.00      1.00      2400\n",
      "       STORE       0.87      0.95      0.91      1211\n",
      "        TIME       1.00      1.00      1.00      1200\n",
      "\n",
      "   micro avg       0.90      0.99      0.94      8411\n",
      "   macro avg       0.91      0.99      0.94      8411\n",
      "weighted avg       0.92      0.99      0.95      8411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 63/63 [00:02<00:00, 26.55it/s, v_num=4, train_loss=0.00158, val_loss=0.00829] \n",
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.96      1.00      0.98      4106\n",
      "     BALANCE       1.00      0.96      0.98      4187\n",
      "        DATE       1.00      1.00      1.00      4000\n",
      "        PAD]       1.00      1.00      1.00      8000\n",
      "       STORE       1.00      1.00      1.00      4052\n",
      "        TIME       1.00      1.00      1.00      4000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99     28345\n",
      "   macro avg       0.99      0.99      0.99     28345\n",
      "weighted avg       0.99      0.99      0.99     28345\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.95      1.00      0.98      1028\n",
      "     BALANCE       1.00      0.96      0.98      1047\n",
      "        DATE       1.00      1.00      1.00      1000\n",
      "        PAD]       1.00      1.00      1.00      2000\n",
      "       STORE       0.96      0.96      0.96      1007\n",
      "        TIME       1.00      1.00      1.00      1000\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7082\n",
      "   macro avg       0.99      0.99      0.99      7082\n",
      "weighted avg       0.99      0.99      0.99      7082\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.46      0.85      0.59      1313\n",
      "     BALANCE       0.66      0.77      0.71      1466\n",
      "        DATE       0.75      1.00      0.86      1200\n",
      "        PAD]       1.00      1.00      1.00      2400\n",
      "       STORE       0.59      0.94      0.72      1208\n",
      "        TIME       0.82      0.82      0.82      1200\n",
      "\n",
      "   micro avg       0.70      0.91      0.79      8787\n",
      "   macro avg       0.71      0.90      0.78      8787\n",
      "weighted avg       0.74      0.91      0.81      8787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, train_test_split\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "folds_res = []\n",
    "for train_val_idx, test_idx in gkf.split(bert_tokens, groups=data_df['type']):\n",
    "    \n",
    "    train_idx , val_idx = train_test_split(train_val_idx, test_size=0.2, random_state=41)\n",
    "\n",
    "    train_tokens = bert_tokens[train_idx]\n",
    "    val_tokens = bert_tokens[val_idx]\n",
    "    test_tokens = bert_tokens[test_idx]\n",
    "\n",
    "    # ---------------------------\n",
    "    train_ds = NerDataset(train_tokens[:,0, : ], train_tokens[:,1, :])\n",
    "    val_ds = NerDataset(val_tokens[:,0, : ], val_tokens[:,1, :])\n",
    "    test_ds = NerDataset(test_tokens[:,0, : ], test_tokens[:,1, :])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=64)\n",
    "    test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = NerModel(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        embedding_dim=512,\n",
    "        hidden_dim=128,\n",
    "        num_layers=1,\n",
    "        num_tags=len(label2id),\n",
    "        lr=1e-3, \n",
    "        l1 = 0, \n",
    "        dropout=0.3 ,\n",
    "        att_heads=2\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize a PyTorch Lightning trainer\n",
    "    trainer = pl.Trainer(max_epochs=10, log_every_n_steps=1, devices=[0], \n",
    "                         callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss', patience=3 , mode='min'), \\\n",
    "                                    pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')])\n",
    "    trainer.fit(model, train_dataloaders=train_loader , val_dataloaders=val_loader)\n",
    "\n",
    "    train_pred , train_true = predictions(model, train_loader, id2label)\n",
    "    val_pred , val_true = predictions(model, val_loader, id2label)\n",
    "    test_pred , test_true = predictions(model, test_loader, id2label)\n",
    "    \n",
    "    # Print a classification report with entity-level metrics\n",
    "    print(\"Train:\")\n",
    "    print(classification_report(train_true, train_pred))\n",
    "    print(\"Validation:\")\n",
    "    print(classification_report(val_true, val_pred))\n",
    "    print(\"Test:\")\n",
    "    print(classification_report(test_true, test_pred))\n",
    "\n",
    "    # trian \n",
    "    f1_train = f1_score(train_true, train_pred , average='macro')\n",
    "    precision_train = precision_score(train_true, train_pred , average='macro')\n",
    "    recall_train = recall_score(train_true, train_pred , average='macro')\n",
    "    accuracy_train = accuracy_score(train_true, train_pred)\n",
    "\n",
    "    # val\n",
    "    f1_val = f1_score(val_true, val_pred , average='macro')\n",
    "    precision_val = precision_score(val_true, val_pred , average='macro')\n",
    "    recall_val = recall_score(val_true, val_pred , average='macro')\n",
    "    accuracy_val = accuracy_score(val_true, val_pred)\n",
    "\n",
    "    # test\n",
    "    f1_test = f1_score(test_true, test_pred , average='macro')\n",
    "    precision_test = precision_score(test_true, test_pred , average='macro')\n",
    "    recall_test = recall_score(test_true, test_pred , average='macro')\n",
    "    accuracy_test = accuracy_score(test_true, test_pred)\n",
    "    \n",
    "    folds_res.append({\n",
    "        \"f1_train\": f1_train,\n",
    "        \"precision_train\": precision_train,\n",
    "        \"recall_train\": recall_train,\n",
    "        \"accuracy_train\": accuracy_train,\n",
    "        \"f1_val\": f1_val,\n",
    "        \"precision_val\": precision_val,\n",
    "        \"recall_val\": recall_val,\n",
    "        \"accuracy_val\": accuracy_val,\n",
    "        \"f1_test\": f1_test,\n",
    "        \"precision_test\": precision_test,\n",
    "        \"recall_test\": recall_test,\n",
    "        \"accuracy_test\": accuracy_test\n",
    "    })\n",
    "\n",
    "folds_res = pd.DataFrame(folds_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1_train           0.995015\n",
       "precision_train    0.993890\n",
       "recall_train       0.996232\n",
       "accuracy_train     0.999839\n",
       "f1_val             0.987596\n",
       "precision_val      0.986586\n",
       "recall_val         0.988719\n",
       "accuracy_val       0.999528\n",
       "f1_test            0.879156\n",
       "precision_test     0.841174\n",
       "recall_test        0.934788\n",
       "accuracy_test      0.992627\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp0' 'temp9' 'temp12' 'temp17' 'temp22' 'temp26' 'temp30']\n",
      "['temp4' 'temp8' 'temp13' 'temp18' 'temp21' 'temp27']\n",
      "['temp1' 'temp5' 'temp14' 'temp19' 'temp23' 'temp28']\n",
      "['temp2' 'temp6' 'temp10' 'temp15' 'temp24' 'temp29']\n",
      "['temp3' 'temp7' 'temp11' 'temp16' 'temp20' 'temp25']\n"
     ]
    }
   ],
   "source": [
    "for train_val_idx, test_idx in gkf.split(bert_tokens, groups=data_df['type']):\n",
    "    print(data_df['type'][test_idx].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_idx, test_idx = train_test_split(range(len(data_df)), test_size=0.2, random_state=41)\n",
    "train_idx , val_idx = train_test_split(train_val_idx, test_size=0.2, random_state=41)\n",
    "\n",
    "train_tokens = bert_tokens[train_idx]\n",
    "val_tokens = bert_tokens[val_idx]\n",
    "test_tokens = bert_tokens[test_idx]\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "train_ds = NerDataset(train_tokens[:,0, : ], train_tokens[:,1, :])\n",
    "val_ds = NerDataset(val_tokens[:,0, : ], val_tokens[:,1, :])\n",
    "test_ds = NerDataset(test_tokens[:,0, : ], test_tokens[:,1, :])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=64)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | embedding | Embedding          | 14.8 M | train\n",
      "1 | lstm      | LSTM               | 657 K  | train\n",
      "2 | attention | MultiheadAttention | 263 K  | train\n",
      "3 | dropout   | Dropout            | 0      | train\n",
      "4 | fc        | Linear             | 3.1 K  | train\n",
      "5 | loss_fn   | CrossEntropyLoss   | 0      | train\n",
      "---------------------------------------------------------\n",
      "15.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.078    Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0: 100%|██████████| 2/2 [00:00<00:00, 166.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 62/62 [00:02<00:00, 26.16it/s, v_num=5, train_loss=0.000918, val_loss=0.00581]\n",
      "Train:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      4133\n",
      "     BALANCE       1.00      1.00      1.00      4288\n",
      "        DATE       1.00      1.00      1.00      3968\n",
      "        PAD]       1.00      1.00      1.00      7936\n",
      "       STORE       1.00      1.00      1.00      4010\n",
      "        TIME       1.00      1.00      1.00      3968\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     28303\n",
      "   macro avg       1.00      1.00      1.00     28303\n",
      "weighted avg       1.00      1.00      1.00     28303\n",
      "\n",
      "Validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      1030\n",
      "     BALANCE       1.00      1.00      1.00      1075\n",
      "        DATE       1.00      1.00      1.00       992\n",
      "        PAD]       1.00      1.00      1.00      1984\n",
      "       STORE       0.94      0.95      0.95      1006\n",
      "        TIME       1.00      1.00      1.00       992\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7079\n",
      "   macro avg       0.99      0.99      0.99      7079\n",
      "weighted avg       0.99      0.99      0.99      7079\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       1.00      1.00      1.00      1284\n",
      "     BALANCE       0.99      1.00      1.00      1337\n",
      "        DATE       1.00      1.00      1.00      1240\n",
      "        PAD]       1.00      1.00      1.00      2480\n",
      "       STORE       0.94      0.95      0.95      1251\n",
      "        TIME       1.00      1.00      1.00      1240\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      8832\n",
      "   macro avg       0.99      0.99      0.99      8832\n",
      "weighted avg       0.99      0.99      0.99      8832\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "\n",
    "# Instantiate the model\n",
    "model = NerModel(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embedding_dim=512,\n",
    "    hidden_dim=128,\n",
    "    num_layers=1,\n",
    "    num_tags=len(label2id),\n",
    "    lr=1e-3, \n",
    "    l1 = 0, \n",
    "    dropout=0.3 ,\n",
    "    att_heads=2\n",
    ")\n",
    "\n",
    "# Initialize a PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=30, log_every_n_steps=1, devices=[0], \n",
    "                     callbacks=[pl.callbacks.EarlyStopping(monitor='val_loss', patience=4, mode='min'), \\\n",
    "                                pl.callbacks.ModelCheckpoint(monitor='val_loss', save_top_k=1, mode='min')])\n",
    "trainer.fit(model, train_dataloaders=train_loader , val_dataloaders=val_loader)\n",
    "\n",
    "train_pred , train_true = predictions(model, train_loader, id2label)\n",
    "val_pred , val_true = predictions(model, val_loader, id2label)\n",
    "test_pred , test_true = predictions(model, test_loader, id2label)\n",
    "\n",
    "# Print a classification report with entity-level metrics\n",
    "print(\"Train:\")\n",
    "print(classification_report(train_true, train_pred))\n",
    "print(\"Validation:\")\n",
    "print(classification_report(val_true, val_pred))\n",
    "print(\"Test:\")\n",
    "print(classification_report(test_true, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(token, label, tokenizer, print_res = True): \n",
    "    sample_label = label\n",
    "    sample_token = token\n",
    "    amount_t = sample_token[np.where((sample_label == 'B-AMOUNT')  | (sample_label == 'I-AMOUNT'))[0]]\n",
    "    store_t = sample_token[np.where((sample_label == 'B-STORE')  | (sample_label == 'I-STORE'))[0]]\n",
    "    balance_t = sample_token[np.where((sample_label == 'B-BALANCE')  | (sample_label == 'I-BALANCE'))[0]]\n",
    "    date_t = sample_token[np.where((sample_label == 'B-DATE')  | (sample_label == 'I-DATE'))[0]]\n",
    "    time_t = sample_token[np.where((sample_label == 'B-TIME')  | (sample_label == 'I-TIME'))[0]]\n",
    "\n",
    "    message = tokenizer.decode(sample_token)\n",
    "    amount = tokenizer.decode(amount_t)\n",
    "    store = tokenizer.decode(store_t)\n",
    "    balance = tokenizer.decode(balance_t)\n",
    "    date = tokenizer.decode(date_t)\n",
    "    time = tokenizer.decode(time_t)\n",
    "\n",
    "    if print_res : \n",
    "        print(f\"Message: {message}\")\n",
    "        print(f\"Amount: {amount}\")\n",
    "        print(f\"Store: {store}\")\n",
    "        print(f\"Balance: {balance}\")\n",
    "        print(f\"Date: {date}\")\n",
    "        print(f\"Time: {time}\")\n",
    "    return message, amount, store, balance, date, time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: [CLS] Debit Notification : QAR 1, 498. 13 was withdrawn from your account ( ending * * * 627768 ) via card * * * * 5943 for a transaction at qhxPQ 4HVwH on 28 / 11 / 23 at 15 : 12. Your updated balance is QAR 1, 657. 66. Please review your account activity for any discrepancies. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 1, 498. 13\n",
      "Store: qhxPQ 4HVwH\n",
      "Balance: 1, 657. 66\n",
      "Date: 28 / 11 / 23\n",
      "Time: 15 : 12\n",
      "\n",
      "\n",
      "Message: [CLS] Transaction Alert : A purchase of 128. 20 was made at lMtDDMZo - lG OXW using card * * * * 4985 on 05 / 02 / 20 at 19 : 12. Remaining balance : 8, 441. 80. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 128. 20\n",
      "Store: lMtDDMZo - lG OXW\n",
      "Balance: 8, 441. 80\n",
      "Date: 05 / 02 / 20\n",
      "Time: 19 : 12\n",
      "\n",
      "\n",
      "Message: [CLS] Your card * * * * 9803 was used at nhvqb QryTIdfxjGrz for a 411. 83 transaction on 10 / 05 / 21 at 24 : 52. Balance stands at 7, 736. 04. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 411. 83\n",
      "Store: nhvqb QryTIdfxjGrz\n",
      "Balance: 7, 736. 04\n",
      "Date: 10 / 05 / 21\n",
      "Time: 24 : 52\n",
      "\n",
      "\n",
      "Message: [CLS] Alert : QAR 1, 063. 41 was spent at pYUCsNdlq6n CS vpxc on 04 / 05 / 22 at 20 : 37. Your account ending * * * 699413 now has a balance of QAR 2, 709. 44. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 1, 063. 41\n",
      "Store: pYUCsNdlq6n CS vpxc\n",
      "Balance: 2, 709. 44\n",
      "Date: 04 / 05 / 22\n",
      "Time: 20 : 37\n",
      "\n",
      "\n",
      "Message: [CLS] Debit Notification : QAR 95. 74 was withdrawn from your account ( ending * * * 468326 ) via card * * * * 4192 for a transaction at Nt - Q9 7JA - PlIQ7RSAh on 14 / 08 / 23 at 17 : 37. Your updated balance is QAR 8, 091. 33. Please review your account activity for any discrepancies. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 95. 74\n",
      "Store: Nt - Q9 7JA - PlIQ7RSAh\n",
      "Balance: 8, 091. 33\n",
      "Date: 14 / 08 / 23\n",
      "Time: 17 : 37\n",
      "\n",
      "\n",
      "Message: [CLS] Transaction Notification : 246. 31 charged at eRyaj0kf 8T pocs using card * * * * 2319 on 10 / 11 / 24 23 : 14. Remaining balance : 8, 859. 52. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 246. 31\n",
      "Store: eRyaj0kf 8T pocs\n",
      "Balance: 8, 859. 52\n",
      "Date: 10 / 11 / 24\n",
      "Time: 23 : 14\n",
      "\n",
      "\n",
      "Message: [CLS] FYI : A 995. 08 purchase at pzlBJOfnvtNF2Ao on 01 / 08 / 21 at 18 : 26 was made on account * * * 914944. Balance : 1, 406. 99. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 995. 08\n",
      "Store: pzlBJOfnvtNF2Ao\n",
      "Balance: 1, 406. 99\n",
      "Date: 01 / 08 / 21\n",
      "Time: 18 : 26\n",
      "\n",
      "\n",
      "Message: [CLS] Alert : Your card * * * * 6693 was used at VL95iy2rc1j6gUYunpcJNoB on 07 / 01 / 23 at 15 : 34 for an amount of 1, 499. 34. Your available balance is 6, 853. 77. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 1, 499. 34\n",
      "Store: VL95iy2rc1j6gUYunpcJNoB\n",
      "Balance: 6, 853. 77\n",
      "Date: 07 / 01 / 23\n",
      "Time: 15 : 34\n",
      "\n",
      "\n",
      "Message: [CLS] Reminder : Debit of 1, 414. 57 from saving account * * * 451890 for your purchase at RJXZw81VvKVh2nj - MM8 on 26 / 09 / 21 at 24 : 34. New balance : 2, 952. 76. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 1, 414. 57\n",
      "Store: RJXZw81VvKVh2nj - MM8\n",
      "Balance: 2, 952. 76\n",
      "Date: 26 / 09 / 21\n",
      "Time: 24 : 34\n",
      "\n",
      "\n",
      "Message: [CLS] FYI : A 729. 33 purchase at lMoInL9rZJsQ on 22 / 09 / 21 at 23 : 38 was made on account * * * 101258. Balance : 2, 946. 93. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 729. 33\n",
      "Store: lMoInL9rZJsQ\n",
      "Balance: 2, 946. 93\n",
      "Date: 22 / 09 / 21\n",
      "Time: 23 : 38\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = np.random.choice(range(len(test_pred)), 10)\n",
    "for idx in idxs : \n",
    "    _ = decode(test_tokens[idx][0], np.array(test_pred[idx]), tokenizer)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>card_number</th>\n",
       "      <th>amount</th>\n",
       "      <th>store</th>\n",
       "      <th>account</th>\n",
       "      <th>balance</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debit transaction of QAR 1,298.13 from Card **...</td>\n",
       "      <td>****4953</td>\n",
       "      <td>1,298.13</td>\n",
       "      <td>SMAISMA CAFE          DOHQA</td>\n",
       "      <td>***704063</td>\n",
       "      <td>830.52</td>\n",
       "      <td>1/1/2024</td>\n",
       "      <td>13:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Debit transaction of QAR 413.48 from Card ****...</td>\n",
       "      <td>****9448</td>\n",
       "      <td>413.48</td>\n",
       "      <td>Qatar Charity          doha</td>\n",
       "      <td>***663320</td>\n",
       "      <td>4,188.75</td>\n",
       "      <td>1/2/2024</td>\n",
       "      <td>2:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Debit transaction of QAR 723.33 from Card ****...</td>\n",
       "      <td>****9858</td>\n",
       "      <td>723.33</td>\n",
       "      <td>MONOPRIX HYPERMARKET  DOHDOHA</td>\n",
       "      <td>***459249</td>\n",
       "      <td>5,390.72</td>\n",
       "      <td>1/5/2024</td>\n",
       "      <td>20:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debit transaction of QAR 493.88 from Card ****...</td>\n",
       "      <td>****8611</td>\n",
       "      <td>493.88</td>\n",
       "      <td>GOOGLE *Forest Focus f</td>\n",
       "      <td>***682551</td>\n",
       "      <td>3,835.47</td>\n",
       "      <td>1/6/2024</td>\n",
       "      <td>9:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Debit transaction of QAR 884.19 from Card ****...</td>\n",
       "      <td>****5724</td>\n",
       "      <td>884.19</td>\n",
       "      <td>AL MAHA AUTO SPARE PARDOHA</td>\n",
       "      <td>***303376</td>\n",
       "      <td>4,988.11</td>\n",
       "      <td>1/6/2024</td>\n",
       "      <td>21:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Debit transaction of QAR 1,429.01 from Card **...</td>\n",
       "      <td>****2219</td>\n",
       "      <td>1,429.01</td>\n",
       "      <td>MINISTER OF FOREIGN AFDOHA</td>\n",
       "      <td>***511450</td>\n",
       "      <td>4,335.05</td>\n",
       "      <td>12/27/2024</td>\n",
       "      <td>5:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Debit transaction of QAR 138.83 from Card ****...</td>\n",
       "      <td>****1223</td>\n",
       "      <td>138.83</td>\n",
       "      <td>SANDWHICH POORI   KARA  D</td>\n",
       "      <td>***418630</td>\n",
       "      <td>8,602.99</td>\n",
       "      <td>12/28/2024</td>\n",
       "      <td>6:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Debit transaction of QAR 138.97 from Card ****...</td>\n",
       "      <td>****8807</td>\n",
       "      <td>138.97</td>\n",
       "      <td>ORANGE MINI HYPERMARKEDOHA</td>\n",
       "      <td>***696471</td>\n",
       "      <td>9,385.77</td>\n",
       "      <td>12/29/2024</td>\n",
       "      <td>10:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Debit transaction of QAR 61.75 from Card ****9...</td>\n",
       "      <td>****9099</td>\n",
       "      <td>61.75</td>\n",
       "      <td>WOQOD - UMM EBAIRIYA SDRD</td>\n",
       "      <td>***329114</td>\n",
       "      <td>4,186.89</td>\n",
       "      <td>12/30/2024</td>\n",
       "      <td>24:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Debit transaction of QAR 895.97 from Card ****...</td>\n",
       "      <td>****2213</td>\n",
       "      <td>895.97</td>\n",
       "      <td>MINISTRY OF INTERIOR   doha</td>\n",
       "      <td>***259085</td>\n",
       "      <td>7,152.98</td>\n",
       "      <td>12/31/2024</td>\n",
       "      <td>8:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   sms card_number    amount  \\\n",
       "0    Debit transaction of QAR 1,298.13 from Card **...    ****4953  1,298.13   \n",
       "1    Debit transaction of QAR 413.48 from Card ****...    ****9448    413.48   \n",
       "2    Debit transaction of QAR 723.33 from Card ****...    ****9858    723.33   \n",
       "3    Debit transaction of QAR 493.88 from Card ****...    ****8611    493.88   \n",
       "4    Debit transaction of QAR 884.19 from Card ****...    ****5724    884.19   \n",
       "..                                                 ...         ...       ...   \n",
       "359  Debit transaction of QAR 1,429.01 from Card **...    ****2219  1,429.01   \n",
       "360  Debit transaction of QAR 138.83 from Card ****...    ****1223    138.83   \n",
       "361  Debit transaction of QAR 138.97 from Card ****...    ****8807    138.97   \n",
       "362  Debit transaction of QAR 61.75 from Card ****9...    ****9099     61.75   \n",
       "363  Debit transaction of QAR 895.97 from Card ****...    ****2213    895.97   \n",
       "\n",
       "                             store    account   balance        date      time  \n",
       "0      SMAISMA CAFE          DOHQA  ***704063    830.52    1/1/2024     13:43  \n",
       "1      Qatar Charity          doha  ***663320  4,188.75    1/2/2024      2:25  \n",
       "2    MONOPRIX HYPERMARKET  DOHDOHA  ***459249  5,390.72    1/5/2024     20:11  \n",
       "3           GOOGLE *Forest Focus f  ***682551  3,835.47    1/6/2024      9:12  \n",
       "4       AL MAHA AUTO SPARE PARDOHA  ***303376  4,988.11    1/6/2024     21:31  \n",
       "..                             ...        ...       ...         ...       ...  \n",
       "359     MINISTER OF FOREIGN AFDOHA  ***511450  4,335.05  12/27/2024      5:11  \n",
       "360      SANDWHICH POORI   KARA  D  ***418630  8,602.99  12/28/2024      6:00  \n",
       "361     ORANGE MINI HYPERMARKEDOHA  ***696471  9,385.77  12/29/2024     10:14  \n",
       "362      WOQOD - UMM EBAIRIYA SDRD  ***329114  4,186.89  12/30/2024  24:14:00  \n",
       "363    MINISTRY OF INTERIOR   doha  ***259085  7,152.98  12/31/2024      8:19  \n",
       "\n",
       "[364 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load true data \n",
    "real_data_df = pd.read_csv(\"data/rand_data.csv\")\n",
    "real_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df['sms'] = real_data_df['sms'].apply(lambda x : x.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ner_data = []\n",
    "for index, row in real_data_df.iterrows():\n",
    "    labeled_tokens = label_tokens(row['sms'],  row['amount'], row['store'], row['balance'], row['date'], row['time'], max_len=50)\n",
    "    real_ner_data.append(labeled_tokens)  # Add a blank line to separate sentences\n",
    "real_ner_data = np.array(real_ner_data)\n",
    "\n",
    "real_tokens = tokenize_data(tokenizer, real_ner_data, label2id, IGNORE_INDEX, max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ds = NerDataset(real_tokens[:,0, : ], real_tokens[:,1, :])\n",
    "real_loader = DataLoader(real_ds, batch_size=64)\n",
    "\n",
    "real_pred , real_true = predictions(model, real_loader, id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s7seg\\.conda\\envs\\mlops\\Lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: [PAD] seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AMOUNT       0.74      0.94      0.83       634\n",
      "     BALANCE       0.79      0.84      0.81       634\n",
      "        DATE       0.96      0.98      0.97       634\n",
      "        PAD]       1.00      1.00      1.00      1268\n",
      "       STORE       0.39      0.70      0.50       646\n",
      "        TIME       0.58      1.00      0.73       634\n",
      "\n",
      "   micro avg       0.73      0.92      0.81      4450\n",
      "   macro avg       0.74      0.91      0.81      4450\n",
      "weighted avg       0.78      0.92      0.83      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_true, real_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9847634069400631\n",
      "F1: 0.806764705908598\n",
      "Precision: 0.7424728328741431\n",
      "Recall: 0.9086809387543827\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(real_true, real_pred)\n",
    "f1 = f1_score(real_true, real_pred , average='macro')\n",
    "precision = precision_score(real_true, real_pred , average='macro')\n",
    "recall = recall_score(real_true, real_pred , average='macro')\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pred = np.array(real_pred)\n",
    "real_true = np.array(real_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: [CLS] Debit transaction of QAR 2. 00 from Card * * * 2 at ORANGE MINI HYPERMARKEDOHA from Current Account 01 * * * 390038 New Balance : QAR 284. 59 If you suspect this transaction call 44192022 30 / 07 / 24 12 : 18 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 2. 00\n",
      "Store: ORANGE MINI HYPERMARKEDOHA\n",
      "Balance: 284. 59\n",
      "Date: 30 / 07 / 24\n",
      "Time: 12 : 18\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 21. 00 from Card * * * 2 at WOQOD - BU FASSELA SIDA D from Current Account 01 * * * 390038 New Balance : QAR 3, 316. 12 If you suspect this transaction call 44192022 30 / 12 / 24 10 : 03 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 21. 00\n",
      "Store: WOQOD - BU FASSELA SIDA D\n",
      "Balance: 3, 316. 12\n",
      "Date: 30 / 12 / 24\n",
      "Time: 10 : 03\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 6. 00 from Card * * * 2 at NEW AL ZARKA RESTAURAN D from Current Account 01 * * * 390038 New Balance : QAR 1, 017. 86 If you suspect this transaction call 44192022 12 / 12 / 24 07 : 46 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 6. 00\n",
      "Store: NEW AL ZKA RESTAURAN D\n",
      "Balance: 1, 017. 86\n",
      "Date: 12 / 12 / 24\n",
      "Time: ##22 07 : 46\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 25. 00 from Card * * * 2 at TEA TIME DOHA from Current Account 01 * * * 390038 New Balance : QAR 15, 822. 41 If you suspect this transaction call 44192022 31 / 08 / 24 13 : 27 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 25. 00\n",
      "Store: TEA TIME DOHA\n",
      "Balance: 15, 822. 41\n",
      "Date: 31 / 08 / 24\n",
      "Time: ##22 13 : 27\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 16. 00 from Card * * * 2 at Thaam Al Shaay DOHDOHA from Current Account 01 * * * 390038 New Balance : QAR 1, 234. 15 If you suspect this transaction call 44192022 18 / 08 / 24 12 : 24 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 16. 00\n",
      "Store: Thaam Shaay DOHDOHA20\n",
      "Balance: 1, 234. 15\n",
      "Date: 18 / 08 / 24\n",
      "Time: ##22 12 : 24\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 50. 00 from Card * * * 2 at MIRAJ ISTANBUL REST DOHDOHA from Current Account 01 * * * 390038 New Balance : QAR 17, 503. 10 If you suspect this transaction call 44192022 31 / 05 / 24 23 : 07 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 50. 00\n",
      "Store: MIRAJ ISTANBUL REST DOHDOHA\n",
      "Balance: 17, 503. 10\n",
      "Date: 31 / 05 / 24\n",
      "Time: ##22 23 : 07\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 40. 00 from Card * * * 2 at ALMASRI RESTAURANT DOHA from Current Account 01 * * * 390038 New Balance : QAR 2, 285. 55 If you suspect this transaction call 44192022 11 / 07 / 24 18 : 21 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 40. 00\n",
      "Store: ALMASRI RESTAURANT DOHA\n",
      "Balance: 2, 285. 55\n",
      "Date: 11 / 07 / 24\n",
      "Time: ##22 18 : 21\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 17. 00 from Card * * * 2 at Thaam Al Shaay DOHDOHA from Current Account 01 * * * 390038 New Balance : QAR 535. 09 If you suspect this transaction call 44192022 25 / 07 / 24 12 : 15 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 17. 00\n",
      "Store: Thaam Shaay DOHDOHA\n",
      "Balance: 535. 09\n",
      "Date: 25 / 07 / 24\n",
      "Time: 12 : 15\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 55. 00 from Card * * * 2 at QATAR CHARITY MPGS from Current Account 01 * * * 390038 New Balance : QAR 641. 02 If you suspect this transaction call 44192022 27 / 10 / 24 20 : 52 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 55. 00\n",
      "Store: ##ATITY MPGS20\n",
      "Balance: 641. 02\n",
      "Date: 27 / 10 / 24\n",
      "Time: ##22 20 : 52\n",
      "\n",
      "\n",
      "Message: [CLS] Debit transaction of QAR 115. 00 from Card * * * 2 at DECATHLON DFC DOHA from Current Account 01 * * * 390038 New Balance : QAR 14, 126. 42 If you suspect this transaction call 44192022 10 / 09 / 24 21 : 01 [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "Amount: 115. 00\n",
      "Store: DECATHLON DFC DOHA\n",
      "Balance: 14, 126. 42\n",
      "Date: 10 / 09 / 24\n",
      "Time: ##22 21 : 01\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = np.random.choice(range(len(real_pred)), 10)\n",
    "for idx in idxs : \n",
    "    _ = decode(real_tokens[idx][0], real_pred[idx], tokenizer)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
